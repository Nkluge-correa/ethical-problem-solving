# Low

EPS uses an evaluation matrix to calculate impacts associated with an application. The three categories in this matrix are **Low**, **Intermediate**, and **High**. From low to high, each category has a set of suggestions to guide future implementations.

EPS measures the level of impact of an application regarding truthfulness through how likely it is to cause harm if its outputs are not entirely truthful. An application with a **low level of impact** is unlikely to cause harm if its outputs are not factual, given that outputs do not necessitate to be correlated with a specific ground truth.

The following intended uses are representative of the Low-impact level:

- **Art-generators:** Generative AI that reproduces different artistic styles â€“ and other creative elements like shapes, colors, and textures.

- **Video Games:** Generative AI can be used to create dynamic and evolving in-game environments, NPC characters, dialogues, and scenarios.

- **Animation and Visual Effects:** Generative AI can assist in creating complex animation sequences or visual effects that would be time-consuming and expensive to produce manually.

The following recommendations are related to the principle of **truthfulness** in applications with a **Low** level of impact.

## Recommendations

An application with a **low level of impact** should implement the following measures:

- **Disclosure:** Non-disclosure of AI involvement can lead to a sense of deception, especially if users are unaware that they are interacting with an AI system.

## How to increase Truthfulness?

### Disclosure

Generative AI systems can produce content that closely resembles humane activities. That is why disclosure is crucial to inform users when AI-generated content is part of an interaction with a system or application.

With disclosure, users become aware that they are engaging with an AI, avoiding potential confusion or misunderstanding about the origin and reliability of the information provided. Also, disclosure should empower users by giving them the necessary information to make informed decisions on whether to trust the output of a particular system or not. When users know the presence of generative AI, they can adjust their expectations and behaviors accordingly. Disclosure statements can be included as **user warnings**, information within the **Terms of Service** or **User Policy**, etc. Improving upon this idea, organizations can also implement **legal disclaimers** to further protect themselves against legal liability.

The importance of disclosure is not exclusive to generative AI; it extends to all AI systems, especially in applications where AI influences choices or decisions. In the end, whether it's decision-making algorithms, image recognition models, or recommendation engines, disclosure helps avoid confusion and deception. To learn about disclosure effects on user interactions with AI, we recommend the following studies ([source](https://arxiv.org/abs/2303.06217), [source](https://arxiv.org/abs/2311.15544)).
